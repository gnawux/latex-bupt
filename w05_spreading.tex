%$Id: w05_spreading.tex gnawux $
%  vim: set ft=tex:
\chapter{移动个人网络中的分布式系统信息存储}

\section{引言}

分布式终端系统中的高级节点的关键任务之一是维护系统的状态，即分布式地存储系统中的可用资源信息与系统中的业务应用的状态信息，保障这些信息在移动过程中的可靠性和节点大量变动的情况下数据存取的高效性，同时，数据维持工作也应该较低地消耗节点的计算、存储、通信带宽和能量资源，尽量少地影响系统中运行的其它应用。

作为一个分布式系统，分布式终端系统可以采用有中心或者无中心两大类方式来存储这些系统中的资源和状态信息，前者的优点在于数据的组织管理开销比较低，只有少数中心节点需要维护管理数据、处理数据一致性问题，但是，由于用户周边设备的稳定性较低、能力有限，这种依赖于少数节点的工作方式的可靠性和可扩展性都比较有限；另一方面，从~20~世纪末开始，对等网络~(P2P)~技术逐渐在互联网上流行并进一步拓展到包括移动自组织网络在内的各种计算机网络之上，通过节点间的协同来存储数据，不再受限于单一节点的能力，完全避免了中心节点失效导致整个系统无法工作的问题，极大地提高了系统的可用性和可扩展性。

本章试图通过对移动个人网络中的系统相关信息与其工作方式的分析，给出一种与其他相关工作相比适用于此种网络的系统信息的分布式存储方式。

\section{分布式系统的系统资源数据存储}

本章所考虑的分布式资源存储并非一个分布式文件系统，因为这里要存储的数据规格一致、具有很强的结构性，即系统可用资源描述与应用状态，而并不存在非格式化、二进制数据，不存在目录、管道、链接等特殊类型，因此，其存储的数据实际是一些目录数据，除了数据库之外，很多其它互联网上的协议~(如表~\ref{tab:dirproto}~所列)~也都支持这类操作，其共性是
\begin{itemize}
	\item 以~``请求/响应''~方式工作，发出查询请求、得到查询结果；
	\item 查询请求可以通过某些限制条件获得符合条件的若干记录，或得到请求无法满足的响应结果；
	\item 响应结果使用协议规定的标准格式，具有明确语义；
	\item 部分协议支持~``注册/声明''~操作，用以发布信息。
\end{itemize}
其工作方式如图~\ref{fig:dirproto}~所示。

\begin{table}[tb]
	\centering
	\begin{tabular}{lp{.6\textwidth}}
		\hline
		协议名称 & 描述 \\
		\hline
		SLP		& Service Location Protocol (RFC2608), 服务定位协议 \\
		LDAP	& Lightweight Directory Location Protocol, 轻量级目录访问协议 \\
		NIS     & Network Information Service, 网络信息服务~(黄页服务) \\
		DNS		& Domain Name Service, 域名服务\\
		Jini	& Jini\texttrademark~的核心之一是一个查询服务\\
		SSDP	& Simple Service Discovery Protocol, 简单服务发现协议，UPnP~中的服务发现协议\\
		\hline
	\end{tabular}
	\caption{具有类似目录查询工作方式的网络协议举例}
	\label{tab:dirproto}
\end{table}

\begin{figure}[tb]
	\begin{center}
		\includegraphics[width=.5\textwidth]{luproto}
	\end{center}
	\caption{目录查询工作方式示意}
	\label{fig:dirproto}
\end{figure}

作为网络通信协议，表~\ref{tab:dirproto}~所列的协议一般都只规范网络上传播的~``查询/注册''~消息，而不规范数据的存储方式，在通常的实现中，这些目录数据会存储于服务器本地的数据结构之中，但通过构建一个~P2P~的层叠网络，将数据存储于这个网络之内，也可以完成类似的工作。

\subsection{传统的有中心存储方式}

对于表~\ref{tab:dirproto}~中所述的协议，它们的工作的基础都需要首先设定或得到一个目录服务器的地址，以~SLPv2 (SLP~版本~2)~为例，服务提供者~(称为服务代理，Service Agent, SA)~或作为服务的使用者的应用~(称为用户代理，User Agent, UA)~可以通过主动和被动两种方法获得提供目录的服务器~(目录代理，Directory Agent, DA)~的地址，而其它协议中，目录服务器的地址则更多依赖于手工指定或是通过自动配置过程~(如~DHCP)~获取。由于这些目录服务的地址一般是一个或几个单播~IP~地址，因此，传统的目录信息的存储方式也天然地是有中心的。

有中心的存储方式在网络中面临着两个主要问题：
\begin{itemize}
	\item 由于网络连接和服务器自身的可靠性是有限的，中心节点或关键链路失效会导致尽管整个系统的大部分元素工作正常，但服务却无法正常进行。
	\item 由于中心节点的存储、计算能力和通信带宽都是有限的，当系统的规模增大的时候，中心节点相关的性能将成为整个系统的瓶颈。
\end{itemize}

当然，有中心架构并非只有一个节点，通过多个中心节点进行互相备份与负载均衡，有中心的存储方式可以在一定程度上缓解这一可靠性和可伸缩性的问题。然而，对于移动个人网络所在的个人域环境，由于个人域设备的能力和可靠性都难以保障，少量的备份不足以让移动个人网络有效避免这一问题，因此，本论文考虑将存储的信息更进一步的分布化，使用无中心架构来存储目录信息。

%As a centralized directory such as that in Service Location Protocol (SLP) or Jini is hard to survive in mobility event of mobile personal networks, decentralized directory and data replication among nodes are adopted in order to improve the robustness. Discrete Hash Table (DHT) based methods, such as chord  and pastry , enable a distributed storage infrastructure for Internet, however, each node in a DHT ring should keep routing information of $O(\log{}N)$ peers and an additional node's joining costs a lookup ($O(\log{}N)$ messages) and updating routing informations in $O(\log{}N)$ nodes . As the nodes often joining a mobile personal network as groups, DHT based infrastructure may not handle it effectively. 

\subsection{非结构化无中心数据存储}

对等~(Peer-to-Peer, P2P)~架构是有别于~``客户机-服务器''~架构的一种分布式系统架构模型，因为不区分客户机与服务器，所以也被称为无中心架构，自从~20~世纪末在文件共享领域被广泛使用之后，逐步引起更多研究者的注意，其突出优点是所有参与者都是客户机也都是服务器，因此不存在任何会影响整个系统工作的关键点，呈现出很强的自组织特性。在诸如~Gnutella~等早期纯粹的~P2P~网络协议中，所有的节点之间是完全没有组织的，节点之间的信息查找使用所谓的~``泛洪''~方式，即从一点起，向所有已知的节点散播查询消息，借到查询消息的节点会把用同样方法得到的信息返回给查找者，当然，一次查找所散播的跳数被限制在一个很有限的值之内，以避免过长的响应时间以及过度占用网络带宽。

由于节点间的松散关系，与下文将要提到的~``结构化''~P2P~相对应，这种基于泛洪式查询的无中心存储架构被称为非结构化的~P2P~架构，这种架构的优点和缺点都十分明显，它的突出优点在于没有任何组织开销，不需要任何节点为整个系统的组织负责，工作方式稳定而可靠，然而，它所带来的最显著的缺点就在于~``不确定性''，即当一次查找没有得到结果的时候，发起查找的客户端无法确定被查找者是根本不存在还是恰恰在自己查找范围之外一点点而已，另一个缺点就是~``泛洪''~式的通信会对网络带宽有较大的影响，且不可管控。

\subsection{结构化无中心数据存储}\label{sss:05:structp2p}

所谓~``结构化''~无中心架构是利用某种映射关系，将系统中存储的元素与存储这些元素的节点相对应起来，从而可以在有限步骤内，查询到一个元素或是确定地知道该元素不存在。一种比较常见的用于结构化~P2P~中查询机制的映射关系是所谓的分布式哈希表~(Distributed Hashing Table, DHT)，即使用一个哈希函数处理存储节点的名称~(地址)~和要存储的数据的名称，将所得到的哈希值排列在一个圆周之上，把哈希值相邻的两个节点~$N_k$~和~$N_{k+1}$~之间的所有要存储的数据都交给节点~$N_k$~来保存，也就是说，当希望找到哈希值为~$h$~的数据元素，只要找到哈希值刚刚好~``小于''~$h$~的节点查询一下就可以了，记该节点的值为~$\lfloor h\rfloor$，这里，``小于''~是圆周上的小于，如果哈希函数的值域是~$\left[0,H\right)$~的话，$0$~是大于~$H-1$~的。

对于~DHT~方法来说，各个不同的协议或机制的差异就在于给定一个哈希值~$h$，如何找到哈希值为~$\lfloor h\rfloor$~的节点。比较容易理解的方式是每个节点都保存它下一个节点的地址和哈希值，构成一个环形的链，只要一环一环地找，就可以找到需要的节点，这个方法的复杂度显然是~$O(N)$~的，相比于泛洪工作方式的指数蔓延速度，这个确定性的代价实在是太大了。于是，Chord、Pastry~等基于~DHT~的机制都让每个节点多存储一些相关节点的信息，从而加速这个查找过程，以~Chord~为例，通过付出每个节点存储~$O(\log(N))$~个相关节点的信息的代价，使得这个查询过程的复杂度可以减少到~$O(\log(N))$，从而进入一个可以接受的范围。当然，存储相关节点的信息越多，当节点发生变更的时候，在系统中受影响的节点也就越多，管理维护开销也就越大。

DHT~方法中，通过节点之间的交互，逐步地查找目的节点，这一过程和网络层的路由有些类似，只是发生在应用层。除了层面的区别之外，另一个区别就是查找所依据的键值，网络层查找依赖于网络地址，这个地址强烈地反映了节点之间的拓扑位置关系，地址越接近，两个节点之间也越接近，而~DHT~方法的~``应用层路由''~则是完全的数学意义上的接近，和拓扑位置的接近完全无关，因此，这层覆盖在网络层以上的层叠网络~(Overlay)~带来的数据分布在拓扑上的无规律性对于负载均衡等很多考量都是十分有益的，但同时，对于消息传播的效率是也有一定影响。

\section{移动个人网络的分布式数据存储}

具体地考虑移动个人网络中的分布式数据存储，作为~MANET~的一个子集，移动个人网络同样是没有任何基础设施，具有很强的对等与自组织性，这与无中心的应用~Overlay~非常类似，而且，由于移动个人网络中，并不假设设备具有高性能与高可用性，需要避免因部分设备失效而带来的系统服务中断。因此，有必要将移动个人网络中的所有具有一定能力的节点，即高级节点，组织起来，成为一个分布式系统信息存储~Overlay。

对于移动个人网络来说，结构化和非结构化的~P2P~方式均有其各自的不足：非结构化无中心的~P2P~分布式系统通常用于资源共享，没有固定的存储机制，不存在一个确定的~``存储元素-存储节点''~的映射关系，而分布式终端系统则需要一个相对可靠的存储机制，这使得非结构化~P2P~难堪重用。

然而，对于我们的应用，结构化~P2P~也具有它自己的显著不足，回顾~\S~\ref{sss:03:mpnchar}，我们注意到，移动个人网络中的一个重要的移动性特征就是大量节点的同时加入与退出，而正如~\S~\ref{sss:05:structp2p}~所述，结构化的~P2P~方式为了在维护和查询效率中取得折衷，不得不在每个节点上保存~$O(\log(N))$~的其他节点的路由信息，而这些信息会导致每个新加入节点需要一定的时间才能有效地融入系统，达到稳定状态。以~Chord~为例，如果加入节点的速度低于修复路由信息的速度，可以维持基本相同的查询效率，而当大量节点同时加入时，不可避免地会带来更高的维护开销和更长的达到稳定所需的时间。

在这一方面，非结构化由于其无状态性，反而具有较好的性能，不需要过多的维护开销，而且，基于~\S~\ref{sss:03:mpnchar}~的分析，由于移动个人网络中链路数量有限，泛洪搜索方式所造成的冲击是有限的。这样，论文考虑将结构化~P2P~中的确定性部分地引入到非结构化~P2P~的基础架构之中，构成一种~``半确定性''~架构，达到效率和可靠性的折衷。

若移动个人网络中有~$n$~个节点，$N_1, N_2,\cdots,N_n$，它们分布在网络中的~$l$~个异构链路~$L_1, L2,\cdots,L_l$~上，其中有~$s$~个高级节点~($N_{S_1}, N_{S_2},\cdots,N_{S_s}$)~可以用于存储系统信息。当发生移动事件的时候，原有高级节点上的数据需要在变化之后的~$n'$~个节点中的~$s'$~个高级节点中重新分布，
\begin{eqnarray}
	n' = & \!\!\!\!n+\Delta{}n, & \Delta{}n > -n\\
	s' = & \!\!\!\!s+\Delta{}s, & \Delta{}s > -s\\
	      &	    		& 0\le{}\frac{\Delta{}s}{\Delta{}n}\le{}1.\nonumber
	\label{equ:nodesch}
\end{eqnarray}

移动个人网络中所涉及到的系统信息分为两类，其一是设备提供的能力服务器的描述信息，另一类则是系统中的应用会话相关信息。如表~\ref{tab:server}，一个能力服务器的描述信息不仅包含它的标识~(ServerID)、其提供的服务类型与能力等信息，同时还包括一个组标识~(GroupID)~用于描述其所在的组，这些信息可以用于帮助在服务发现的过程中应用选择恰当的服务器。而应用的描述信息~(表~\ref{tab:app})~则用于保存应用状态、维持业务连续性，其中包含了应用的~ID~和正在使用的或需要的能力服务器的相关描述。这样，如果系统现有能力无法维持业务继续运行则会终止应用，如果系统中有了新的能力服务器可用可以通知应用，甚至在能力服务器发生更替的时候可以及时利用先有资源重新生成业务、维持业务的连续性，这里，用于回调的地址可以是本地移动个人网络中的，也可以包含广域网络中的远程服务器地址描述。

\begin{table}
	\centering
	\caption{能力服务器的描述信息}
	\label{tab:server}
	\begin{tabular}{lll}
		\hline
		数据字段		& 描述内容							& 数据类型	\\
		\hline
		ServiceTypeID	& 服务器提供的服务类型				& string	\\
		ServerID		& 能力服务器的惟一标识				& string	\\
		DeviceID		& 提供能力服务器的设备			 	& string 	\\
		GroupID 		& 能力服务器所在设备的所属组		& string 	\\
		NormalizedCapa 	& 能力服务器的归一化能力描述		& integer 	\\
		UsedBy			& 目前使用此能力的应用				& string	\\
		TTL				& 此能力服务器描述的有效期			& integer	\\
		Capability		& 服务器能力的具体描述				& string	\\
		\hline
	\end{tabular}
\end{table}

\begin{table}
	\centering
	\caption{应用会话的描述信息}
	\label{tab:app}
	\begin{tabular}{lll}
		\hline
		数据字段		& 描述内容							& 数据类型	\\
		\hline
		AppID			& 应用会话的惟一标识				& string \\
		Location		& 应用的回调接口地址				& string	\\
		Required		& 应用所必须的能力服务器及能力		& string	\\
		Recommended		& 应用所需的其他能力服务器及能力	& string	\\
		Using			& 当前使用的能力服务器				& string	\\
		\hline
	\end{tabular}
\end{table}

所有这些记录都是由一组给定的键值对~(AVP, Attribute Value Pair)~组成的记录信息，并且具有各自的惟一标识，通过将这些数据放入统一的目录之中，即可通过各种组合查询手段找到需要的能力服务器或应用会话相关信息。而上述两类信息作为服务发现机制的数据源和结果又具有一些不同属性，例如，能力服务器信息是依附于其所在设备的，而设备是具有成组移动特性；相反，应用是全局性的信息，不带有分组性，并且，在发生移动的时候，业务应尽量保持连续性。

%In proposed protocol, only application entries are maintained system-wise so that the applications can be recomposed even if serving devices leave the system, while the CS entries of devices are maintained in the scope of group, therefore, the minimization of system-wise status \cite{bib:prehofer05} cuts down the cost of reorganizing the directory. All the SNs in mobile personal networks have some memory for maintaining a database of the directory entries for service discovery.
%后面分析中可以考虑把分布范围放在组或全局，考量不同的性能影响，不过下面那个一定是考虑组移动性的否则似乎优点不大


\subsection{移动个人网络数据的无中心组织方法}

%尽量减少全局状态，以组为单位是个折衷，全局信息全局存储，小组信息小组存储
对于全局信息的存储，为了均衡各个节点的负担，提高系统的可靠性和可伸缩性，论文中采用了一种将数据以无中心方式分布到各个节点之上的方法，并通过一定的冗余度，保障在节点大规模损失的情况下的数据可靠性。数据信息会被组播到所有的高级节点，而每个高级节点都通过一个自己的优先级算法，将优先级较高的一些记录保存在自己的存储空间之中，而不保存优先级较低的记录。每条记录~(r)~在特定节点~(n)~的优先级~($P_n(r)$)~的计算是通过一个哈希函数~($h(\cdot)$)~来实现的：定义记录的~ID~和节点的~ID~哈希值的距离为该记录在此节点上的存储优先级
\begin{equation}
	P_{n}(r)=d(h(r)-h(n))
	\label{eq:priority}
\end{equation}
这里，哈希值的分布特性将决定存储的分布特征，为了保证数据分布的均匀性，论文选择了常用的~SHA-1~算法作为哈希函数，对于非特殊选择的~ID，其哈希值应遵循均匀分布。在这种情况下，对于存储于~$s$~个高级节点中的~$r$~条信息，如果每个高级节点存储~$\gamma$~条信息，则信息冗余度大致为
\begin{equation}
	\rho=\frac{\gamma{}s}{r}.
	\label{eq:redundancy}
\end{equation}
对于哈希函数一定的取值范围，上述距离实际是一个圆周距离的概念，如图~\ref{fig:hashoverview}，高级节点会优先保存哈希值具体自己的哈希值比较近的~$R$~条记录，当记录条目比较多的时候，一个节点的覆盖范围就比较狭窄，而当记录条目较少的时候，节点发覆盖范围就比较宽，而冗余度本身则取决于节点的覆盖范围和节点密度两者的比值。

\begin{figure}[htb]
	\begin{center}
		\includegraphics[width=.9\textwidth]{hash-overview}
	\end{center}
	\caption{高级节点所保存的记录的键值范围示意}
	\label{fig:hashoverview}
\end{figure}

\section{目录数据向新加入节点传播}

在发生服务发现事件的时候，高级节点会自然地更新其存储的数据，除此之外，它们还通过目录更新消息来更新彼此存储的目录信息，每个高级节点都会以一定时间周期来公布它所存储的目录数据，这个更新周期~$T_u$~是由其上一次收到目录更新消息的时间~$T_{u0}$~和其存储的目录数据所确定的
\begin{equation}
	T_u = T_{u0} + T_r\cdot{}(R-R_D+1),
	\label{eqn:tupdate}
\end{equation}
其中，$T_r$~是一个均匀分布的随机变量，用以避免碰撞，$R$~是本节点所存储的目录数据的总量，而~$R_D$~是目录中较老的，没有在近期内被更新过的记录的数量，也就是说，有较多未被更新的数据的节点更倾向于较早地发送更新消息。一旦有新节点加入到移动个人网络之中，它们可以通过的目录更新消息得初始化本地目录信息，随后，与正常的目录更新过程一样，它们可以利用得到的目录更新消息调整目录内容，在若干个更新周期之后达到稳定状态。图~\ref{fig:spread-stat}~是单个高级节点的目录数据更新的状态图，图~\ref{fig:replica}~是这一过程的伪代码。

\begin{figure}[tb]
	\begin{center}
		\includegraphics[width=.7\textwidth]{spread-st}
	\end{center}
	\caption{高级节点目录更新状态转移图}
	\label{fig:spread-stat}
\end{figure}

\begin{figure}[htb]
	\begin{center}
	\framebox{%
	\begin{minipage}[t]{.9\textwidth}%
	\texttt{%
\mbox{~}on\_timeout()\\
\mbox{~}\hspace{4ex} sent\_update();\\
\mbox{~}\\
\mbox{~}on\_receive\_solicitation()\\
\mbox{~}\hspace{4ex} t = timer.get\_time();\\
\mbox{~}\hspace{4ex} timer.set\_time( t/entry\_number );\\
\mbox{~}\\
\mbox{~}on\_receive\_update()\\
\mbox{~}\hspace{4ex} time\_stamp = systemtime();\\
\mbox{~}\hspace{4ex} update\_entries(received\_data,time\_stamp);\\
\mbox{~}\hspace{4ex} entry\_diff\_count=0;\\
\mbox{~}\hspace{4ex} for i=1 to record\_number\\
\mbox{~}\hspace{4ex}\hspace{4ex}  if entry[i].time\_stamp < (time\_stamp-threshold)\\
\mbox{~}\hspace{4ex}\hspace{4ex}\hspace{4ex}   entry\_diff\_count++;\\
\mbox{~}\hspace{4ex} timer.set\_time(rand()*\\
\mbox{~}\hspace{4ex}\hspace{4ex}\hspace{4ex}\hspace{4ex}\hspace{4ex} (entry\_number-entry\_diff\_number+1));%  
	}%
	\end{minipage}%
	}
	\end{center}
	\caption{目录更新过程的伪代码}
	\label{fig:replica}
\end{figure}

由于目录更新消息是在高级节点之间以组播方式传送的，因此，当同时加入节点的数量增加的时候，目录达到稳定的时间不会线性增长，达到稳定的时间至多不会比所有的高级节点将全部目录数据发送出来。

假设当前的网络中有~$s$~个已经处于稳定状态的高级节点，这些节点中所有记录都处于未过期状态，即~$R_D=0$，这时，每个节点的定时器溢出时间都服从一个区间~$[T_{u0},T_{u0}+T_{ur}]$~上的均匀分布，其中~$T_{ur}=T_r\cdot (R+1)$，而对于正个系统来说，发送的时间将是所有节点发送定时器溢出时间的最小值
\begin{equation}
	t_{sent}=\min_{i=1}^{s}\left(T_{u0}+t_i\right)
	\label{equ:tomin}
\end{equation}
其中，$t_i$~是区间~$[0,T_{ur}]$~上服从均匀分布的随机变量，$T_{u0}+t_i$~是节点~$i$~的定时器溢出时间。这样，目录更新消息发送时间早于~$T_{u0}+x$~的概率为
\begin{eqnarray}
	F\left(t_{sent}<T_{u0}+x\right) & = & F\left(\min_{i=1}^s\left(t_i\right)<x\right)\nonumber\\
	                                & = & 1 - F\left(t_1>x,t_2>x,\cdots,t_s>x\right)
	\label{eq:propsent1}
\end{eqnarray}
不妨设各个节点的计时器溢出时间的概率分布是独立的，这样
\begin{equation}
	F\left(t_{sent}<T_{u0}+x\right)  =  1 - \prod_{i=1}^{s}F\left(t_i>x\right)
	\label{eq:propsent2}
\end{equation}
由于各个节点的计时器溢出时间都遵循均匀分布随机，所以
\begin{equation}
	F\left(t_{sent}<T_{u0}+x\right) = \begin{cases}
		1 - \frac{\left(T_{ur}-x\right)^s}{\left(T_{ur}\right)^s} & \text{if} \quad 0 \le x \le T_{ur} \\
		0                                            & \text{otherwise}
	\end{cases}
	\label{eq:propsent3}
\end{equation}
这样，目录更新消息发送，即最短计时器溢出时间的概率密度函数$\frac{dF}{dx}$为
\begin{equation}
	f\left(x\right)=\begin{cases}
		\frac{s\left(T_{ur} - x\right)^{s-1}}{T_{ur}^s} & \text{if} \quad 0 \le x \le T_{ur}\\
		0 & \text{otherwise}
	\end{cases}
	\label{eq:propdense}
\end{equation}
图~\ref{fig:propdense}~绘制出了~$T_{ur}$~归一化的不同的~$s$~值对应的更新发送时间的概率密度函数，可以看到，网络中的高级节点越多，发送目录更新消息的时间也就越早，其期望值是
\begin{eqnarray}
	E(x) & = & \int_{-\infty}^{\infty}x\cdot f(x)\,dx \nonumber\\
	     & = & \int_{0}^{T_{ur}} \frac{s x \left(T_{ur} - x\right)^{s-1}}{T_{ur}^s} dx \nonumber\\
     	 & = & \frac{ T_{ur}}{ \left( s + 1 \right)}
	\label{eq:expectsent}
\end{eqnarray}

\begin{figure}[tb]
	\begin{center}
		\includegraphics[width=.6\textwidth]{propdense}
	\end{center}
	\caption{目录更新消息发送时间的概率密度函数}
	\label{fig:propdense}
\end{figure}

当所有节点的数据记录都处在未过期状态时，各个节点以均等概率发送目录更新消息，如图~\ref{fig:hashoverlap}~所示的圆周上，若每个节点的覆盖范围的夹角为~$\theta=\frac{2\pi R}{R_{all}}$，其中~$R_{all}$~为总记录数，R~为每个节点存储的记录条数，两个节点之间的夹角为~$\phi$，则当~$\phi\ge\theta$~时两者不存在交叠区域，发送信息的总量即为~$2R$，否则，两次发送信息的总量存在一个交叠区域，两者覆盖面积总和为~$\theta+\phi$，发送的记录条数为~$\frac{R_{all}\left(\theta+\phi\right)}{2\pi}$。由于各个节点以均等概率发送目录更新消息，$\phi$~遵循~$[0,2\pi]$~上的均匀分布，所以，两次发送信息总量的数学期望~$E(R_s)$~为
\begin{eqnarray}
	E(R_s)  & = & \int_{0}^{2\pi}R_s(\phi)f(\phi)d\phi \nonumber\\
			& = & 2\int_{0}^{\theta}\frac{R_{all}(\theta+\phi)}{2\pi}\frac{1}{2\pi}d\phi%
			         + 2\int_{\theta}^{\pi}2R\frac{1}{2\pi}d\phi \nonumber\\
					 & = & (2-\frac{R}{R_{all}})\cdot R
	\label{eq:allsent}
\end{eqnarray}

\begin{figure}[tb]
	\begin{center}
		\includegraphics[width=.7\textwidth]{hash-overlap}
	\end{center}
	\caption{高级节点存储覆盖范围之间的交叠情况}
	\label{fig:hashoverlap}
\end{figure}

现在考虑两个节点所包含的较老数据记录数量不同的情况，假设两节点的~$R-R_D+1$~值分别为~$r_0$~和~$r_0+r$，其中~$r_0 \ge 1,r > 0, r_0+r \le R$，则两个节点的发送时间~$t_1$~和~$t_2$~将分别服从区间~$[T_{u0},T_{u0}+T_r\cdot r_0]$~和区间~$[T_{u0},T_{u0}+T_r\cdot\left(r_0+r\right)]$，这样，$t_1<t_2$~的概率则为
\begin{eqnarray}
	F(t_1<t_2) & = & \int_{-\infty}^{\infty}\int_{-\infty}^{t_2}f(t_1)f(t_2) dt_1 dt_2 \nonumber\\
	           & = & \int_{T_{u0}}^{T_{u0}+T_r\cdot r_0}\!\int_{T_{u0}}^{t_2}\frac{1}{T_r\cdot r_0}\cdot\frac{1}{T_r\cdot\left(r_0+r\right)}dt_1 dt_2 \nonumber\\
			   &   &  + \int_{T_{u0}+T_r\cdot r_0}^{T_{u0}+T_r\cdot\left(r_0+r\right)}\frac{1}{T_r\cdot\left(r_0+r\right)}dt_2\nonumber\\
			   & = & \frac{r_0+2r}{2(r0+r)}\nonumber\\
			   & = & 1-\frac{r_0}{2(r0+r)}
	\label{eq:proplt1}
\end{eqnarray}
也就是说，随着~$r$~的增加，具有较多较老数据记录的节点具有更高的较早发送目录更新消息的概率，当~$r>\!\!>r_0$~的时候，这一概率也趋近于~1。

由上述分析可知，在新节点加入过程中，

表~\ref{tab:exam}~是一个节点加入过程的例子：假设原有~15~个高级节点，每个节点存储~8~条目录记录，而总共有~30~条记录，这样，每条记录大约有~4~个备份。表中情况为~4~个高级节点同时加入，它们通过目录更新消息来进行初始化。表~\ref{tab:exam}~中，每个表格代表了一个更新周期，表格的第一行则表示更新消息的内容，圆括号里的数字是发送目录更新消息的节点的编号；表中的其它每行都是代表一个新加入节点的目录内容，其中的内容是按照每条记录在该节点内的优先级来排序的，每次更新后新增加的记录用下划线标明。

如表~\ref{tab:exam}~所示，第一个更新周期之后，所有的新加入高级节点都使用来自~$s_6$~的更新消息进行了初始化。之后，使用来自~$s_5$~的更新消息，第一个新加入节点的数据几乎被完全更新，实际已经达到了稳定状态，而第二个新加入节点也向着稳定状态迈进了一步，其它两个节点则没有更新。最后，在第三个更新周期之中，所有新加入节点都同时进入了稳定状态。

\begin{table}[htb]
	\centering
	\caption{例：4~个高级节点加入一个原有~15~个高级节点的网络}
	\label{tab:exam}
	\begin{tabular}{p{10ex}|rrrrrrrr}
		\hline
		Updates(6) & 	12 &   9 &   1 &  21 &  19 &  17 &  24 &  6 \\
		\hline
		1			&	6  & 24  & 17  & 21  & 19  &  9  &  1  & 12 \\
		2			&	6  & 21  &  9  & 12  &  1  & 19  & 17  & 24 \\
		3			&   21 &   9 &  12 &   1 &   6 &  19 &  17 &  24 \\
		4			&	9  & 12  &  1  & 21  & 19  & 17  &  6  & 24 \\
		\hline
	\end{tabular}
	\vspace{1em}

	\begin{tabular}{p{10ex}|rrrrrrrr}
		\hline
		Updates(5) & 	13 &  27 &  15 &  14 &   7 &   5 &  11 &  16 \\
		\hline
		1			&   \underline{13} &  \underline{27} &  \underline{15} &  \underline{14} &   \underline{7} &   \underline{5} &  \underline{11} &  \underline{16} \\
		2			&    6 &  \underline{16} &  \underline{11} &   \underline{5} &  21 &   \underline{7} &   9 &  12 \\
		3			&   21 &   9 &  12 &   1 &   6 &  19 &  17 &  24 \\
		4			&    9 &  12 &   1 &  21 &  19 &  17 &   6 &  24 \\
		\hline
	\end{tabular}
	\vspace{1em}
	
	\begin{tabular}{p{10ex}|rrrrrrrr}
		\hline
		Updates(13) &   10 &  30 &   3 &  22 &  28 &   8 &   6 &   2 \\
		\hline
		1			&   13 &  27 &  15 &  14 &   7 &   5 &  11 &  16 \\
		2			&   \underline{28} &  \underline{22} &   \underline{3} &  \underline{30} &  \underline{10} &   \underline{2} &   \underline{8} &   6 \\
		3			&   21 &   9 &  12 &   1 &   6 &   \underline{8} &  \underline{10} &  19 \\
		4			&    9 &  12 &   1 &  21 &  19 &  17 &   6 &   \underline{8} \\
		\hline
	\end{tabular}
\end{table}

可以看到，所有节点的目录条目更新是并行进行的。诸如~chord~等~DHT~类的分布式存储算法，并不考虑这种大量节点同时加入的情况，而论文所述的方法因为更新消息是组播到所有高级节点的，所以，不仅可以平稳地处理这些节点的同时加入，而且可以以较高的效率并行处理，甚至在新加入高级节点的数量超过原有高级节点数量的时候也可以稳定工作。图~\ref{fig:spread}~所示的仿真工作就表明了这一点。

\begin{figure}[htb]
	\begin{center}
		\includegraphics[width=.7\textwidth]{images/spread}
	\end{center}
	\caption{Effects of Joining Nodes and Updating Period}
	\label{fig:spread}
\end{figure}

如图~\ref{fig:spread}，同样假设原有~15~个高级节点，每个节点存储总共~30~条目录条目中的~8~条，当加入的高级节点数目分别为~$1, 2, 4, 8,\cdots,128$~个的时候，随着加入节点数量的指数增长，新加入节点所需要的目录更新周期数量以一条想对平缓的曲线增长，这一增长是由于新加入的未稳定节点同样参与了竞争发送目录更新消息的行列，从而延缓了整个系统中达到稳定状态的时间。
%计算一下，多一个节点发送完整数据所需要的时间长多少，也就是说，n+1 中，n 发送的概率有多高，这个还比较难说
另外，更新消息发送计时器的设置会影响各个高级节点发送更新消息的概率，图~\ref{fig:spread}~显示，较高的更新计时器定时值设置可以帮助新加入节点尽早达到稳定状态，因为这样可以让较老的数据更快地被标记为过期，从而增大发送概率。

\section{节点退出时数据的存活能力}

论文所述方法中，每个节点所保存的记录条目是一定的，这样，当节点~ID~的哈希值和存储数据的哈希值分布均匀的时候，可以趋近于式~\ref{eq:redundancy}~所述的理想冗余度，而在~Chord~等完全结构化~P2P~系统中，通过确保每个数据存储在~$r$~个节点之上，在哈希值分布均匀的情况下，每个节点所保存的记录条目数是趋于稳定值的。

\section{查找数据的性能}

确知的知道多少步骤可以找到所需数据

\section{小结}

